{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embeddins test\n",
    "\n",
    "The following class parse the Python code using AST(Abstract Syntaxt Tree)"
   ],
   "id": "bca717a0d66657d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:04:43.259457Z",
     "start_time": "2024-10-18T15:04:43.239828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "for var, value in dotenv_values(\"../.env.local\").items():\n",
    "    os.environ[var] = value\n",
    "    \n",
    "os.environ[\"DATABASE_URL\"] = \"postgresql://postgres:postgres@localhost:63045/postgres\""
   ],
   "id": "5b84638a8d864e8f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ensure env vars are loaded",
   "id": "532de76168baf95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:05:01.605971Z",
     "start_time": "2024-10-18T15:05:01.597237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib import reload\n",
    "from labs.config import settings\n",
    "\n",
    "reload(settings)\n",
    "\n",
    "print(settings.DATABASE_URL)\n",
    "print(settings.DATABASE_HOST)\n",
    "print(settings.DATABASE_PORT)"
   ],
   "id": "1113d481afff446c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:postgres@localhost:63045/postgres\n",
      "localhost\n",
      "63045\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:05:10.576972Z",
     "start_time": "2024-10-18T15:05:04.365569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from labs import tasks\n",
    "\n",
    "repo_destination = \"/local-repos/revent-api\"\n",
    "issue_body = \"Add created_at and updated_at field to User model\"\n",
    "\n",
    "tasks.run.init_task()\n",
    "tasks.llm.vectorize_repo_to_database_task(repo_destination=repo_destination)\n",
    "similar_embeddins = tasks.llm.find_similar_embeddings_task(issue_body=issue_body)\n",
    "llm_context = tasks.llm.prepare_prompt_and_context_task(issue_body=issue_body, embeddings=similar_embeddins)\n",
    "llm_response = tasks.llm.get_llm_response_task(context=llm_context)\n",
    "tasks.repo.apply_code_changes_task(llm_response=llm_response)"
   ],
   "id": "2ee533cc243b2b80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://raw.githubusercontent.com:443 \"GET /BerriAI/litellm/main/model_prices_and_context_window.json HTTP/1.1\" 200 11887\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "\u001B[92m16:05:06 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:99 - Exception import enterprise features No module named 'litellm.proxy.enterprise'\n",
      "DEBUG:LiteLLM:Exception import enterprise features No module named 'litellm.proxy.enterprise'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/Users/runtime/Documents/Projectos/labs/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/Users/runtime/Documents/Projectos/labs/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:celery.utils.functional:\n",
      "def init_task(self, **kwargs):\n",
      "    return 1\n",
      "\n",
      "DEBUG:celery.utils.functional:\n",
      "def vectorize_repo_to_database_task(prefix=0, repo_destination=1):\n",
      "    return 1\n",
      "\n",
      "[2024-10-18 16:05:08,f][DEBUG][labs.decorators]: Running vectorize_to_database(<labs.database.vectorize.factory.VectorizeFactory object at 0x1123fa060>, None, '/local-repos/revent-api') {} at 2024-10-18 16:05:08.228277.\n",
      "[2024-10-18 16:05:08,f][DEBUG][labs.decorators]: Running vectorize_to_database(<labs.database.vectorize.factory.VectorizeFactory object at 0x1123fa060>, None, '/local-repos/revent-api') {} at 2024-10-18 16:05:08.228277.\n",
      "[2024-10-18 16:05:08,f][DEBUG][labs.database.vectorize.chunk_vectorizer]: Loading and splitting all documents into chunks.\n",
      "[2024-10-18 16:05:08,f][DEBUG][labs.database.vectorize.chunk_vectorizer]: Loading and splitting all documents into chunks.\n",
      "[2024-10-18 16:05:08,f][DEBUG][labs.database.vectorize.chunk_vectorizer]: Embedding all repo documents.\n",
      "[2024-10-18 16:05:08,f][DEBUG][labs.database.vectorize.chunk_vectorizer]: Embedding all repo documents.\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - \n",
      "\n",
      "DEBUG:LiteLLM:\n",
      "\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - \u001B[92mRequest to litellm:\u001B[0m\n",
      "DEBUG:LiteLLM:\u001B[92mRequest to litellm:\u001B[0m\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - \u001B[92mlitellm.embedding(model='text-embedding-ada-002', input=[])\u001B[0m\n",
      "DEBUG:LiteLLM:\u001B[92mlitellm.embedding(model='text-embedding-ada-002', input=[])\u001B[0m\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - \n",
      "\n",
      "DEBUG:LiteLLM:\n",
      "\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:261 - self.optional_params: {}\n",
      "DEBUG:LiteLLM:self.optional_params: {}\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "DEBUG:LiteLLM:SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:261 - self.optional_params: {}\n",
      "DEBUG:LiteLLM:self.optional_params: {}\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:344 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'model': 'text-embedding-ada-002', 'input': []}, 'api_base': 'https://api.openai.com/v1'}\n",
      "DEBUG:LiteLLM:PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'model': 'text-embedding-ada-002', 'input': []}, 'api_base': 'https://api.openai.com/v1'}\n",
      "\u001B[92m16:05:08 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - \u001B[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.openai.com/v1 \\\n",
      "-d '{'model': 'text-embedding-ada-002', 'input': []}'\n",
      "\u001B[0m\n",
      "\n",
      "DEBUG:LiteLLM:\u001B[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.openai.com/v1 \\\n",
      "-d '{'model': 'text-embedding-ada-002', 'input': []}'\n",
      "\u001B[0m\n",
      "\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600, 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x1125f9a80>, 'json_data': {'input': [], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=600 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10e9482f0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x10d2fb7d0> server_hostname='api.openai.com' timeout=600\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1125dea20>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Fri, 18 Oct 2024 15:05:09 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'214'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'runtime-revolution'), (b'openai-processing-ms', b'4'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-request-id', b'req_833bfea8b419fa97e4f70591bf011aa5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tZP1Qy3ZSx1uDxm17ARw7oVxC7V.FOqfzGeISj3JQRw-1729263909-1.0.1.1-sKjxCOa01TuDpZwu.slvo5toCmTWeF7XGzCHEfTa4WMym5nAo3nJf4seIlbYKDmDfuu569DzRRg02R8jHCCd_Q; path=/; expires=Fri, 18-Oct-24 15:35:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.cMfIEged2mnvaGKzCIWpzrNDH1gCoNaxUNzaumdNIg-1729263909551-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d496cc44a5e343d-LIS'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"400 Bad Request\" Headers([('date', 'Fri, 18 Oct 2024 15:05:09 GMT'), ('content-type', 'application/json'), ('content-length', '214'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'runtime-revolution'), ('openai-processing-ms', '4'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-reset-requests', '12ms'), ('x-request-id', 'req_833bfea8b419fa97e4f70591bf011aa5'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=tZP1Qy3ZSx1uDxm17ARw7oVxC7V.FOqfzGeISj3JQRw-1729263909-1.0.1.1-sKjxCOa01TuDpZwu.slvo5toCmTWeF7XGzCHEfTa4WMym5nAo3nJf4seIlbYKDmDfuu569DzRRg02R8jHCCd_Q; path=/; expires=Fri, 18-Oct-24 15:35:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.cMfIEged2mnvaGKzCIWpzrNDH1gCoNaxUNzaumdNIg-1729263909551-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d496cc44a5e343d-LIS'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_833bfea8b419fa97e4f70591bf011aa5\n",
      "DEBUG:openai._base_client:Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1025, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/Users/runtime/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 763, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/embeddings'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400\n",
      "DEBUG:openai._base_client:Not retrying\n",
      "DEBUG:openai._base_client:Re-raising status error\n",
      "\u001B[92m16:05:09 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - RAW RESPONSE:\n",
      "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "\n",
      "DEBUG:LiteLLM:RAW RESPONSE:\n",
      "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "\n",
      "\u001B[92m16:05:09 - LiteLLM:DEBUG\u001B[0m: utils.py:238 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "DEBUG:LiteLLM:Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001B[92m16:05:09 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:1696 - Logging Details LiteLLM-Failure Call: []\n",
      "DEBUG:LiteLLM:Logging Details LiteLLM-Failure Call: []\n",
      "\u001B[92m16:05:09 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:2500 - Model is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "DEBUG:LiteLLM:Model is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "\u001B[92m16:05:09 - LiteLLM:DEBUG\u001B[0m: litellm_logging.py:2539 - Standard Logging: created payload - payload: {'id': '47cf4b11-2bf7-44ed-9e95-a778b7f25128', 'call_type': 'embedding', 'cache_hit': False, 'status': 'failure', 'saved_cache_cost': None, 'startTime': 1729263908.237771, 'endTime': 1729263909.525668, 'completionStartTime': 1729263909.525668, 'model': 'text-embedding-ada-002', 'metadata': {}, 'cache_key': None, 'response_cost': 0, 'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0, 'request_tags': [], 'end_user': '', 'api_base': 'https://api.openai.com/v1', 'model_group': '', 'model_id': '', 'requester_ip_address': None, 'messages': [], 'response': {}, 'model_parameters': {}, 'hidden_params': {'model_id': None, 'cache_key': None, 'api_base': None, 'response_cost': None, 'additional_headers': None}, 'model_map_information': {'model_map_key': '', 'model_map_value': None}, 'error_str': 'litellm.BadRequestError: OpenAIException - Error code: 400 - {\\'error\\': {\\'message\\': \"\\'$.input\\' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'}\n",
      "\n",
      "\n",
      "DEBUG:LiteLLM:Standard Logging: created payload - payload: {'id': '47cf4b11-2bf7-44ed-9e95-a778b7f25128', 'call_type': 'embedding', 'cache_hit': False, 'status': 'failure', 'saved_cache_cost': None, 'startTime': 1729263908.237771, 'endTime': 1729263909.525668, 'completionStartTime': 1729263909.525668, 'model': 'text-embedding-ada-002', 'metadata': {}, 'cache_key': None, 'response_cost': 0, 'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0, 'request_tags': [], 'end_user': '', 'api_base': 'https://api.openai.com/v1', 'model_group': '', 'model_id': '', 'requester_ip_address': None, 'messages': [], 'response': {}, 'model_parameters': {}, 'hidden_params': {'model_id': None, 'cache_key': None, 'api_base': None, 'response_cost': None, 'additional_headers': None}, 'model_map_information': {'model_map_key': '', 'model_map_value': None}, 'error_str': 'litellm.BadRequestError: OpenAIException - Error code: 400 - {\\'error\\': {\\'message\\': \"\\'$.input\\' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001B[0m\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/llms/OpenAI/openai.py:1332\u001B[0m, in \u001B[0;36mOpenAIChatCompletion.embedding\u001B[0;34m(self, model, input, timeout, logging_obj, model_response, optional_params, api_key, api_base, client, aembedding)\u001B[0m\n\u001B[1;32m   1331\u001B[0m headers: Optional[Dict] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1332\u001B[0m headers, sync_embedding_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_sync_openai_embedding_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1333\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopenai_client\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopenai_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m   1334\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   1336\u001B[0m \u001B[38;5;66;03m## LOGGING\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/llms/OpenAI/openai.py:1214\u001B[0m, in \u001B[0;36mOpenAIChatCompletion.make_sync_openai_embedding_request\u001B[0;34m(self, openai_client, data, timeout)\u001B[0m\n\u001B[1;32m   1213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/llms/OpenAI/openai.py:1206\u001B[0m, in \u001B[0;36mOpenAIChatCompletion.make_sync_openai_embedding_request\u001B[0;34m(self, openai_client, data, timeout)\u001B[0m\n\u001B[1;32m   1205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1206\u001B[0m     raw_response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwith_raw_response\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1207\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m   1208\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   1210\u001B[0m     headers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(raw_response\u001B[38;5;241m.\u001B[39mheaders)\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/openai/_legacy_response.py:353\u001B[0m, in \u001B[0;36mto_raw_response_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    351\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextra_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m extra_headers\n\u001B[0;32m--> 353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/openai/resources/embeddings.py:125\u001B[0m, in \u001B[0;36mEmbeddings.create\u001B[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[0;32m--> 125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/embeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/openai/_base_client.py:1265\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1262\u001B[0m opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1263\u001B[0m     method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1264\u001B[0m )\n\u001B[0;32m-> 1265\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/openai/_base_client.py:942\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    935\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    940\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    941\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 942\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/openai/_base_client.py:1046\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1045\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1046\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1049\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1050\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1054\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39moptions\u001B[38;5;241m.\u001B[39mget_max_retries(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries) \u001B[38;5;241m-\u001B[39m retries,\n\u001B[1;32m   1055\u001B[0m )\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOpenAIError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/main.py:3499\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(model, input, dimensions, timeout, api_base, api_version, api_key, api_type, caching, user, custom_llm_provider, litellm_call_id, litellm_logging_obj, logger_fn, **kwargs)\u001B[0m\n\u001B[1;32m   3498\u001B[0m     \u001B[38;5;66;03m## EMBEDDING CALL\u001B[39;00m\n\u001B[0;32m-> 3499\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai_chat_completions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3501\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_base\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogging_obj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogging\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_response\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEmbeddingResponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3507\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptional_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptional_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3509\u001B[0m \u001B[43m        \u001B[49m\u001B[43maembedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maembedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3510\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3511\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m custom_llm_provider \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/llms/OpenAI/openai.py:1355\u001B[0m, in \u001B[0;36mOpenAIChatCompletion.embedding\u001B[0;34m(self, model, input, timeout, logging_obj, model_response, optional_params, api_key, api_base, client, aembedding)\u001B[0m\n\u001B[1;32m   1354\u001B[0m error_headers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1355\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[1;32m   1356\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mstatus_code, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e), headers\u001B[38;5;241m=\u001B[39merror_headers\n\u001B[1;32m   1357\u001B[0m )\n",
      "\u001B[0;31mOpenAIError\u001B[0m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/g0/_nt40pwn27n_1vwcj832w0qc0000gn/T/ipykernel_7129/4285937448.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mrepo_destination\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/local-repos/revent-api\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0missue_body\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Add created_at and updated_at field to User model\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mtasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minit_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mtasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvectorize_repo_to_database_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepo_destination\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrepo_destination\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0msimilar_embeddins\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind_similar_embeddings_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0missue_body\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0missue_body\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mllm_context\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprepare_prompt_and_context_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0missue_body\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0missue_body\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msimilar_embeddins\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mllm_response\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_llm_response_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mllm_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/celery/local.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 182\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_current_object\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/celery/app/task.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    410\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    411\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    413\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 414\u001B[0;31m             \u001B[0m_task_stack\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Projectos/labs/labs/tasks/llm.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(prefix, repo_destination)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mapp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mvectorize_repo_to_database_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepo_destination\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mrepo_destination\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mredis_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mprefix\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m_repo_destination\u001B[0m\u001B[0;34m\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mrepo_destination\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mVectorizeFactory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mVectorizerType\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCHUNK\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvectorize_to_database\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepo_destination\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mprefix\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mprefix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projectos/labs/labs/decorators.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[0mstart_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0mend_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0mtotal_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mend_time\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projectos/labs/labs/database/vectorize/factory.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, include_file_extensions, repo_destination)\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mtime_and_log_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mvectorize_to_database\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minclude_file_extensions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepo_destination\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvectorizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvectorize_to_database\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minclude_file_extensions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepo_destination\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Projectos/labs/labs/database/vectorize/chunk_vectorizer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, include_file_extensions, repo_destination)\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[0mfiles_and_texts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetadata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"source\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpage_content\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m         \u001B[0mtexts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfile_and_text\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mfile_and_text\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfiles_and_texts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Embedding all repo documents.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m         \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0membedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"text-embedding-ada-002\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Storing all embeddings.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0mreembed_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiles_and_texts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1078\u001B[0m                     if (\n\u001B[1;32m   1079\u001B[0m                         \u001B[0mliteDebuggerClient\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mliteDebuggerClient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdashboard_url\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1080\u001B[0m                     \u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# make it easy to get to the debugger logs if you've initialized it\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m                         \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34mf\"\u001B[0m\u001B[0;34m\\n Check the log in your dashboard - \u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mliteDebuggerClient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdashboard_url\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1078\u001B[0m                     if (\n\u001B[1;32m   1079\u001B[0m                         \u001B[0mliteDebuggerClient\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mliteDebuggerClient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdashboard_url\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1080\u001B[0m                     \u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# make it easy to get to the debugger logs if you've initialized it\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m                         \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34mf\"\u001B[0m\u001B[0;34m\\n Check the log in your dashboard - \u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mliteDebuggerClient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdashboard_url\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/main.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(model, input, dimensions, timeout, api_base, api_version, api_key, api_type, caching, user, custom_llm_provider, litellm_call_id, litellm_logging_obj, logger_fn, **kwargs)\u001B[0m\n\u001B[1;32m   3818\u001B[0m             \u001B[0mapi_key\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mapi_key\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3819\u001B[0m             \u001B[0moriginal_response\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3820\u001B[0m         \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3821\u001B[0m         \u001B[0;31m## Map to OpenAI Exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3822\u001B[0;31m         raise exception_type(\n\u001B[0m\u001B[1;32m   3823\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3824\u001B[0m             \u001B[0moriginal_exception\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3825\u001B[0m             \u001B[0mcustom_llm_provider\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcustom_llm_provider\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001B[0m\n\u001B[1;32m   8186\u001B[0m             \u001B[0mthreading\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mThread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mget_all_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm_provider\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8187\u001B[0m         \u001B[0;31m# don't let an error with mapping interrupt the user from receiving an error from the llm api calls\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8188\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mexception_mapping_worked\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8189\u001B[0m             \u001B[0msetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"litellm_response_headers\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlitellm_response_headers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 8190\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   8191\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8192\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0merror_type\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlitellm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLITELLM_EXCEPTION_TYPES\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8193\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projectos/labs/.venv/lib/python3.12/site-packages/litellm/utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001B[0m\n\u001B[1;32m   8186\u001B[0m             \u001B[0mthreading\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mThread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mget_all_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm_provider\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8187\u001B[0m         \u001B[0;31m# don't let an error with mapping interrupt the user from receiving an error from the llm api calls\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8188\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mexception_mapping_worked\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8189\u001B[0m             \u001B[0msetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"litellm_response_headers\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlitellm_response_headers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 8190\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   8191\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8192\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0merror_type\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlitellm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLITELLM_EXCEPTION_TYPES\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8193\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mBadRequestError\u001B[0m: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!cd .. && make up",
   "id": "109fdb797bbba3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python ../labs/api/main.py --reload",
   "id": "3b9097dbdf53c2ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test with new embeddings method\n",
    "\n",
    "### Test 1:\n",
    "Results with the new embeddings: loss of practically all code from the file.\n",
    "\n",
    "#### Request data:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"repo_path\": \"/local-repos/revent-api\",\n",
    "  \"issue_text\": \"Add created_at and updated_at field to User model\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Changes made by LLM:\n",
    "\n",
    "File: local_repos/revent-api/photo/models.py\n",
    "\n",
    "```python\n",
    "from django.db import models\n",
    "from django.contrib.auth.models import AbstractUser\n",
    "\n",
    "class User(AbstractUser):\n",
    "    created_at = models.DateTimeField(auto_now_add=True)\n",
    "    updated_at = models.DateTimeField(auto_now=True)\n",
    "```\n",
    "\n",
    "### Test 2:\n",
    "Results with the new embeddings: loss of practically all code from the file.\n",
    "\n",
    "#### Request data:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"repo_path\": \"/local-repos/revent-api\",\n",
    "  \"issue_text\": \"Add created_at and updated_at field to User model. Keep existing code intact\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Changes made by LLM:\n",
    "\n",
    "File: local_repos/revent-api/photo/models.py\n",
    "\n",
    "```python\n",
    "from django.db import models\n",
    "\n",
    "class User(models.Model):\n",
    "    # existing fields\n",
    "    created_at = models.DateTimeField(auto_now_add=True)\n",
    "    updated_at = models.DateTimeField(auto_now=True)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.username\n",
    "```\n",
    "\n",
    "## Results from these changes:\n",
    "\n",
    "A longer delay in the construction of embeddings and in the overall process was noticed. The change made to the method by which the embeddings are built did not yield better results than the previously used method (splitting the files into pieces of a certain size), suggesting that the model may not be giving sufficient importance to the context provided to it.\n",
    "\n",
    "\n",
    "## Test with old embeddings method\n",
    "\n",
    "### Test 3:\n",
    "Result with the previous method: loss of practically all code from the file.\n",
    "\n",
    "#### Request data:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"repo_path\": \"/local-repos/revent-api\",\n",
    "  \"issue_text\": \"Add created_at and updated_at field to User model\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Changes made by LLM:\n",
    "\n",
    "File: local_repos/revent-api/photo/models.py\n",
    "\n",
    "```python\n",
    "\n",
    "from django.db import models\n",
    "from django.contrib.auth.models import AbstractUser\n",
    "from django.utils import timezone\n",
    "import uuid\n",
    "\n",
    "class SoftDeleteModel(models.Model):\n",
    "    is_deleted = models.BooleanField(default=False)\n",
    "\n",
    "    class Meta:\n",
    "        abstract = True\n",
    "\n",
    "class User(AbstractUser, SoftDeleteModel):\n",
    "    id = models.UUIDField(primary_key=True, default=uuid.uuid4)\n",
    "    email = models.TextField(unique=True)\n",
    "    username = models.CharField(\"username\", max_length=150, null=True)\n",
    "    name_first = models.TextField(blank=True, null=True)\n",
    "    name_last = models.TextField(blank=True, null=True)\n",
    "    profile_picture = models.ForeignKey(\n",
    "        \"Picture\",\n",
    "        on_delete=models.SET_NULL,\n",
    "        related_name=\"user_picture\",\n",
    "        blank=True,\n",
    "        null=True,\n",
    "    )\n",
    "    profile_picture_updated_at = models.DateTimeField(blank=True, null=True)\n",
    "    user_handle = models.TextField(unique=True, null=True)\n",
    "    created_at = models.DateTimeField(auto_now_add=True)\n",
    "    updated_at = models.DateTimeField(auto_now=True)\n",
    "\n",
    "    USERNAME_FIELD = \"email\"\n",
    "    EMAIL_FIELD = \"email\"\n",
    "    REQUIRED_FIELDS = [\"first_name\", \"last_name\"]\n",
    "    objects = UserManager()\n",
    "\n",
    "    class Meta:\n",
    "        constraints = [\n",
    "            models.UniqueConstraint(\n",
    "                fields=[\"email\"],\n",
    "                condition=models.Q(is_deleted=\"False\"),\n",
    "                name=\"user_email\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def validate_profile_picture(self):\n",
    "        if not self._state.adding:\n",
    "            old_picture = User.objects.filter(email=self.email).first().profile_picture\n",
    "            if old_picture and self.profile_picture.id != old_picture.id:\n",
    "                self.profile_picture_updated_at = timezone.now()\n",
    "        if self.profile_picture and self.profile_picture.user.email != self.email:\n",
    "            raise ValidationError(\n",
    "                \"The user's profile picture must be owned by the same user.\"\n",
    "            )\n",
    "\n",
    "    def save(self, *args, **kwargs):\n",
    "        self.validate_profile_picture()\n",
    "        super(User, self).save(*args, **kwargs)\n",
    "```\n",
    "\n",
    "### Test 4:\n",
    "Result with the previous method: loss of practically all code from the file.\n",
    "\n",
    "#### Request data:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"repo_path\": \"/local-repos/revent-api\",\n",
    "  \"issue_text\": \"Add created_at and updated_at field to User model. Keep existing code intact\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Changes made by LLM:\n",
    "\n",
    "File: local_repos/revent-api/photo/models.py\n",
    "\n",
    "```python\n",
    "import uuid\n",
    "from django.db import models\n",
    "from django.utils import timezone\n",
    "from django.contrib.auth.models import AbstractUser\n",
    "from .managers import UserManager\n",
    "\n",
    "class User(AbstractUser):\n",
    "    id = models.UUIDField(primary_key=True, default=uuid.uuid4)\n",
    "    email = models.TextField(unique=True)\n",
    "    username = models.CharField(\"username\", max_length=150, null=True)\n",
    "    name_first = models.TextField(blank=True, null=True)\n",
    "    name_last = models.TextField(blank=True, null=True)\n",
    "    profile_picture = models.ForeignKey(\n",
    "        \"Picture\",\n",
    "        on_delete=models.SET_NULL,\n",
    "        related_name=\"user_picture\",\n",
    "        blank=True,\n",
    "        null=True,\n",
    "    )\n",
    "    profile_picture_updated_at = models.DateTimeField(blank=True, null=True)\n",
    "    user_handle = models.TextField(unique=True, null=True)\n",
    "    created_at = models.DateTimeField(auto_now_add=True)\n",
    "    updated_at = models.DateTimeField(auto_now=True)\n",
    "\n",
    "    USERNAME_FIELD = \"email\"\n",
    "    EMAIL_FIELD = \"email\"\n",
    "    REQUIRED_FIELDS = [\"first_name\", \"last_name\"]\n",
    "    objects = UserManager()\n",
    "\n",
    "    class Meta:\n",
    "        constraints = [\n",
    "            models.UniqueConstraint(\n",
    "                fields=[\"email\"],\n",
    "                condition=models.Q(is_deleted=\"False\"),\n",
    "                name=\"user_email\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def validate_profile_picture(self):\n",
    "        if not self._state.adding:\n",
    "            old_picture = User.objects.filter(email=self.email).first().profile_picture\n",
    "            if old_picture and self.profile_picture.id != old_picture.id:\n",
    "                self.profile_picture_updated_at = timezone.now()\n",
    "        if self.profile_picture and self.profile_picture.user.email != self.email:\n",
    "            raise ValidationError(\n",
    "                \"The user's profile picture must be owned by the same user.\"\n",
    "            )\n",
    "\n",
    "    def save(self, *args, **kwargs):\n",
    "        self.validate_profile_picture()\n",
    "        super(User, self).save(*args, **kwargs)\n",
    "```\n",
    "\n",
    "## Original file code:\n",
    "\n",
    "```python\n",
    "import uuid\n",
    "\n",
    "from django.contrib.auth.models import AbstractUser, BaseUserManager\n",
    "from django.db import models, transaction\n",
    "from django.db.models import Count, Max\n",
    "from django.forms import ValidationError\n",
    "from django.utils import timezone\n",
    "\n",
    "from photo.fixtures import (\n",
    "    CANT_VOTE_SUBMISSION,\n",
    "    CONTEST_CLOSED,\n",
    "    OUTDATED_SUBMISSION_ERROR_MESSAGE,\n",
    "    REPEATED_VOTE_ERROR_MESSAGE,\n",
    "    UNIQUE_SUBMISSION_ERROR_MESSAGE,\n",
    "    VALID_USER_ERROR_MESSAGE,\n",
    "    VOTE_UPLOAD_PHASE_NOT_OVER,\n",
    "    VOTING_DRAW_PHASE_OVER,\n",
    "    VOTING_PHASE_OVER,\n",
    "    VOTING_SELF,\n",
    ")\n",
    "from photo.manager import SoftDeleteManager\n",
    "from photo.storages_backend import PublicMediaStorage, picture_path\n",
    "from utils.enums import ContestInternalStates\n",
    "\n",
    "\n",
    "class UserManager(BaseUserManager):\n",
    "    def create_user(self, email, password=None, **kwargs):\n",
    "        if not email:\n",
    "            raise ValueError(\"Email not provided\")\n",
    "        email = self.normalize_email(email)\n",
    "        user = self.model(email=email, **kwargs)\n",
    "        user.set_password(password)\n",
    "        user.save()\n",
    "        return user\n",
    "\n",
    "    def create_superuser(self, email, password=None, **kwargs):\n",
    "        kwargs.setdefault(\"is_active\", True)\n",
    "        kwargs.setdefault(\"is_staff\", True)\n",
    "        kwargs.setdefault(\"is_superuser\", True)\n",
    "        if kwargs.get(\"is_active\") is not True:\n",
    "            raise ValueError(\"Superuser should be active\")\n",
    "        if kwargs.get(\"is_staff\") is not True:\n",
    "            raise ValueError(\"Superuser should be staff\")\n",
    "        if kwargs.get(\"is_superuser\") is not True:\n",
    "            raise ValueError(\"Superuser should have is_superuser=True\")\n",
    "        return self.create_user(email, password, **kwargs)\n",
    "\n",
    "\n",
    "class SoftDeleteModel(models.Model):\n",
    "    is_deleted = models.BooleanField(default=False)\n",
    "    objects = SoftDeleteManager()\n",
    "    all_objects = models.Manager()\n",
    "\n",
    "    @transaction.atomic\n",
    "    def delete(self):\n",
    "        self.is_deleted = True\n",
    "        self.save()\n",
    "\n",
    "    def restore(self):\n",
    "        self.is_deleted = False\n",
    "        self.save()\n",
    "\n",
    "    class Meta:\n",
    "        abstract = True\n",
    "\n",
    "\n",
    "class User(AbstractUser, SoftDeleteModel):\n",
    "    id = models.UUIDField(primary_key=True, default=uuid.uuid4)\n",
    "    email = models.TextField(unique=True)\n",
    "    username = models.CharField(\"username\", max_length=150, null=True)\n",
    "    name_first = models.TextField(blank=True, null=True)\n",
    "    name_last = models.TextField(blank=True, null=True)\n",
    "    profile_picture = models.ForeignKey(\n",
    "        \"Picture\",\n",
    "        on_delete=models.SET_NULL,\n",
    "        related_name=\"user_picture\",\n",
    "        blank=True,\n",
    "        null=True,\n",
    "    )\n",
    "    profile_picture_updated_at = models.DateTimeField(blank=True, null=True)\n",
    "    user_handle = models.TextField(unique=True, null=True)\n",
    "\n",
    "    USERNAME_FIELD = \"email\"\n",
    "    EMAIL_FIELD = \"email\"\n",
    "    REQUIRED_FIELDS = [\"first_name\", \"last_name\"]\n",
    "    objects = UserManager()\n",
    "\n",
    "    class Meta:\n",
    "        constraints = [\n",
    "            models.UniqueConstraint(\n",
    "                fields=[\"email\"],\n",
    "                condition=models.Q(is_deleted=\"False\"),\n",
    "                name=\"user_email\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def validate_profile_picture(self):\n",
    "        if not self._state.adding:\n",
    "            old_picture = User.objects.filter(email=self.email).first().profile_picture\n",
    "            if old_picture and self.profile_picture.id != old_picture.id:\n",
    "                self.profile_picture_updated_at = timezone.now()\n",
    "        if self.profile_picture and self.profile_picture.user.email != self.email:\n",
    "            raise ValidationError(\n",
    "                \"The user's profile picture must be owned by the same user.\"\n",
    "            )\n",
    "\n",
    "    def save(self, *args, **kwargs):\n",
    "        self.validate_profile_picture()\n",
    "        super(User, self).save(*args, **kwargs)\n",
    "\n",
    "\n",
    "class Picture(SoftDeleteModel):\n",
    "    user = models.ForeignKey(\n",
    "        \"User\", on_delete=models.CASCADE, related_name=\"picture_user\"\n",
    "    )\n",
    "    name = models.TextField(blank=True, null=True)\n",
    "    file = models.ImageField(\n",
    "        storage=PublicMediaStorage(),\n",
    "        upload_to=picture_path,\n",
    "    )\n",
    "    likes = models.ManyToManyField(User, related_name=\"picture_likes\", blank=True)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def like_picture(self, user):\n",
    "        if user not in self.likes.filter(id=user):\n",
    "            self.likes.add(user)\n",
    "            self.save()\n",
    "        return self\n",
    "\n",
    "\n",
    "class PictureComment(SoftDeleteModel):\n",
    "    user = models.ForeignKey(\"User\", on_delete=models.CASCADE)\n",
    "    picture = models.ForeignKey(\n",
    "        \"Picture\",\n",
    "        on_delete=models.CASCADE,\n",
    "    )\n",
    "    text = models.TextField()\n",
    "    created_at = models.DateTimeField(auto_now_add=True)\n",
    "\n",
    "\n",
    "class Collection(SoftDeleteModel):\n",
    "    name = models.TextField()\n",
    "    user = models.ForeignKey(\"User\", on_delete=models.CASCADE)\n",
    "    pictures = models.ManyToManyField(\n",
    "        Picture, related_name=\"collection_pictures\", blank=True\n",
    "    )\n",
    "\n",
    "    class Meta:\n",
    "        constraints = [\n",
    "            models.UniqueConstraint(fields=[\"name\", \"user\"], name=\"collection_pk\")\n",
    "        ]\n",
    "\n",
    "    def add_picture(self, picture):\n",
    "        if picture not in self.pictures.filter(id=picture):\n",
    "            self.pictures.add(picture)\n",
    "            self.save()\n",
    "        return self\n",
    "\n",
    "\n",
    "class Contest(SoftDeleteModel):\n",
    "    title = models.TextField()\n",
    "    description = models.TextField()\n",
    "    cover_picture = models.ForeignKey(\n",
    "        \"Picture\",\n",
    "        on_delete=models.SET_NULL,\n",
    "        blank=True,\n",
    "        null=True,\n",
    "    )\n",
    "    prize = models.TextField(null=True, blank=True)\n",
    "    automated_dates = models.BooleanField(default=True)\n",
    "    upload_phase_start = models.DateTimeField(default=timezone.now)\n",
    "    upload_phase_end = models.DateTimeField(null=True, blank=True)\n",
    "    voting_phase_end = models.DateTimeField(null=True, blank=True)\n",
    "    voting_draw_end = models.DateTimeField(null=True, blank=True)\n",
    "    internal_status = models.TextField(\n",
    "        choices=ContestInternalStates.choices, default=ContestInternalStates.OPEN\n",
    "    )\n",
    "    winners = models.ManyToManyField(User, related_name=\"contest_winners\", blank=True)\n",
    "    created_by = models.ForeignKey(\n",
    "        \"User\",\n",
    "        on_delete=models.SET_NULL,\n",
    "        related_name=\"contest_created_by\",\n",
    "        blank=True,\n",
    "        null=True,\n",
    "    )\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "\n",
    "    def validate_user(self):\n",
    "        if not (\n",
    "            self.created_by\n",
    "            and User.objects.filter(email=self.created_by.email).exists()\n",
    "        ):\n",
    "            raise ValidationError(VALID_USER_ERROR_MESSAGE)\n",
    "\n",
    "    def reset_votes(self):\n",
    "        for submission in ContestSubmission.objects.filter(contest=self):\n",
    "            submission.votes.clear()\n",
    "\n",
    "    def close_contest(self):\n",
    "        self.voting_phase_end = timezone.now()\n",
    "        max_votes = ContestSubmission.objects.annotate(\n",
    "            num_votes=Count(\"votes\")\n",
    "        ).aggregate(max_votes=Max(\"num_votes\"))[\"max_votes\"]\n",
    "        submissions_with_highest_votes = ContestSubmission.objects.annotate(\n",
    "            num_votes=Count(\"votes\")\n",
    "        ).filter(num_votes=max_votes, contest=self)\n",
    "\n",
    "        if self.internal_status == ContestInternalStates.DRAW:\n",
    "            self.winners.clear()\n",
    "        for submission in submissions_with_highest_votes:\n",
    "            self.winners.add(submission.picture.user)\n",
    "\n",
    "        if self.winners.count() > 1:\n",
    "            self.internal_status = ContestInternalStates.DRAW\n",
    "            self.reset_votes()\n",
    "        elif self.winners.count() == 0:\n",
    "            self.internal_status = ContestInternalStates.DRAW\n",
    "            all_submissions = ContestSubmission.objects.filter(contest=self)\n",
    "            for submission in all_submissions:\n",
    "                self.winners.add(submission.picture.user)\n",
    "            self.reset_votes()\n",
    "        else:\n",
    "            self.internal_status = ContestInternalStates.CLOSED\n",
    "        self.save()\n",
    "        return self\n",
    "\n",
    "    def save(self, *args, **kwargs):\n",
    "        if self._state.adding:\n",
    "            self.validate_user()\n",
    "        super(Contest, self).save(*args, **kwargs)\n",
    "\n",
    "\n",
    "class ContestSubmission(SoftDeleteModel):\n",
    "    contest = models.ForeignKey(\n",
    "        \"Contest\",\n",
    "        on_delete=models.CASCADE,\n",
    "    )\n",
    "    picture = models.ForeignKey(\n",
    "        \"Picture\",\n",
    "        on_delete=models.CASCADE,\n",
    "    )\n",
    "    submission_date = models.DateTimeField(auto_now_add=True)\n",
    "    votes = models.ManyToManyField(User, related_name=\"submission_votes\", blank=True)\n",
    "\n",
    "    def validate_unique(self, *args, **kwargs):\n",
    "        qs = ContestSubmission.objects.filter(\n",
    "            contest=self.contest, picture__user=self.picture.user\n",
    "        )\n",
    "\n",
    "        if qs.exists() and self._state.adding:\n",
    "            raise ValidationError(UNIQUE_SUBMISSION_ERROR_MESSAGE)\n",
    "\n",
    "    def validate_vote(self):\n",
    "        user_vote = ContestSubmission.objects.filter(\n",
    "            contest=self.contest, votes=self.picture.user\n",
    "        )\n",
    "\n",
    "        if user_vote.exists() and self._state.adding:\n",
    "            raise ValidationError(REPEATED_VOTE_ERROR_MESSAGE)\n",
    "\n",
    "    def validate_submission_date(self):\n",
    "        submission_date = (\n",
    "            self.submission_date if self.submission_date else timezone.now()\n",
    "        )\n",
    "        if self.contest.upload_phase_end is not None and (\n",
    "            not (\n",
    "                self.contest.upload_phase_start\n",
    "                <= submission_date\n",
    "                <= self.contest.upload_phase_end\n",
    "            )\n",
    "        ):\n",
    "            raise ValidationError(OUTDATED_SUBMISSION_ERROR_MESSAGE)\n",
    "\n",
    "    def save(self, *args, **kwargs):\n",
    "        self.validate_unique()\n",
    "        if self._state.adding:\n",
    "            self.validate_submission_date()\n",
    "        super(ContestSubmission, self).save(*args, **kwargs)\n",
    "\n",
    "    def add_vote(self, user):\n",
    "        contest_submissions = ContestSubmission.objects.filter(contest=self.contest)\n",
    "        user_vote = User.objects.filter(id=user).first()\n",
    "\n",
    "        if self.picture.user.id == user_vote.id:\n",
    "            raise ValidationError(VOTING_SELF)\n",
    "\n",
    "        if self.contest.internal_status == ContestInternalStates.CLOSED:\n",
    "            raise ValidationError(CONTEST_CLOSED)\n",
    "\n",
    "        if self.contest.internal_status == ContestInternalStates.DRAW:\n",
    "            if self.contest.voting_draw_end < timezone.now():\n",
    "                raise ValidationError(VOTING_DRAW_PHASE_OVER)\n",
    "            if self.picture.user not in self.contest.winners.all():\n",
    "                raise ValidationError(CANT_VOTE_SUBMISSION)\n",
    "        else:\n",
    "            if (\n",
    "                self.contest.upload_phase_end\n",
    "                and self.contest.upload_phase_end > timezone.now()\n",
    "            ):\n",
    "                raise ValidationError(VOTE_UPLOAD_PHASE_NOT_OVER)\n",
    "            if (\n",
    "                self.contest.voting_phase_end\n",
    "                and self.contest.voting_phase_end < timezone.now()\n",
    "            ):\n",
    "                raise ValidationError(VOTING_PHASE_OVER)\n",
    "\n",
    "        for sub in contest_submissions:\n",
    "            if user_vote in sub.votes.all():\n",
    "                sub.votes.remove(user_vote)\n",
    "        self.votes.add(user)\n",
    "        self.save()\n",
    "        return self\n",
    "```"
   ],
   "id": "dd392fcfdd550d8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "94a32c3ee811ff1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
